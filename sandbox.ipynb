{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tiktoken\n",
    "import PyPDF2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "max_iters = 3000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-2\n",
    "eval_iters = 200\n",
    "n_embd = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class utilities:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def print(self, string:str, new_line=True):\n",
    "        if new_line:\n",
    "            string = string + \"\\n\"\n",
    "        sys.stdout.write(string)\n",
    "    \n",
    "    \n",
    "    def print_filler(self, myString:str, filler_char='#'):\n",
    "        total_len = len(myString)\n",
    "        filler = []\n",
    "        for i in range(total_len):\n",
    "            filler.append(filler_char)\n",
    "        filler = ''.join(filler)\n",
    "        self.print(filler)\n",
    "\n",
    "    \n",
    "    def read_pdf(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            content = ''\n",
    "            \n",
    "            for i in range(num_pages):\n",
    "                page = pdf_reader.pages[i]\n",
    "                content += page.extract_text()\n",
    "        \n",
    "        return content.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embed):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)                   # (B, T, C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T))    # (T, C)\n",
    "        x = tok_emb + pos_emb\n",
    "        logits = self.lm_head(x)                                    # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "\n",
    "    def generate(self, idx, max_new_tokens):                    # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(idx)                    # Get prediction\n",
    "            logits = logits[:, -1, :]                           # Focus only on the last time step\n",
    "            probs = F.softmax(logits, dim=-1)                   # Apply softmax to get probabilities\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # Sample from distribution\n",
    "            idx = torch.cat((idx, idx_next), dim=1)             # Append sampled index to running seqence\n",
    "        \n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customGPT_trainer(BigramLanguageModel, utilities):\n",
    "    def __init__(self, path) -> None:\n",
    "        '''\n",
    "        METADATA\n",
    "        self.enc -> self.__init__()\n",
    "        self.vocab_size -> self.__init__()\n",
    "        self.original_data -> self.load_data()\n",
    "        self.data -> self.load_data()\n",
    "        '''\n",
    "        # self.enc = tiktoken.get_encoding(\"gpt2\")\n",
    "        # self.vocab_size = self.enc.n_vocab\n",
    "        \n",
    "        self.load_data(path)\n",
    "        self.stoi = {ch:i for i, ch in enumerate(self.chars)}\n",
    "        self.itos = {i:ch for i, ch in enumerate(self.chars)}\n",
    "        self.encode = lambda s: [self.stoi[c] for c in s]\n",
    "        self.decode = lambda l: ''.join([self.itos[i] for i in l])\n",
    "        \n",
    "        # Hacky encoder\n",
    "        data = self.encode(self.original_data)\n",
    "        self.data = torch.tensor(data, dtype=torch.long)\n",
    "\n",
    "        super().__init__(vocab_size=self.vocab_size, n_embed=n_embd)\n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    # def encode_data(self, data):\n",
    "    #     encoded = self.enc.encode(data)\n",
    "    #     return encoded\n",
    "    \n",
    "\n",
    "    # def decode_data(self, encoded_data):\n",
    "    #     decoded = self.enc.decode(encoded_data)\n",
    "    #     return decoded\n",
    "    \n",
    "    \n",
    "    def load_data(self, path:str):\n",
    "        if '.pdf' in path:\n",
    "            data = self.read_pdf(path)\n",
    "        else:\n",
    "            data = \"\"\n",
    "        \n",
    "        # Load Original Data\n",
    "        self.original_data = data\n",
    "        self.chars = sorted(list(set(self.original_data)))\n",
    "        self.vocab_size = len(self.chars)\n",
    "\n",
    "        # Encode data\n",
    "        # data = self.enc.encode(data)\n",
    "        # data = self.encode(self.original_data)\n",
    "        # self.data = torch.tensor(data, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    def split_data_train_val(self, thresh=0.9):\n",
    "        n = int(thresh*len(self.data))\n",
    "        self.train_data = self.data[:n]\n",
    "        self.val_data = self.data[n:]\n",
    "\n",
    "\n",
    "    def generate_batches(self, split:str, batch_size:int=4, block_size:int=8):\n",
    "        data = self.train_data if split == 'train' else self.val_data\n",
    "        ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "        x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "        y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "    def train_model(self, batch_size=32, n_steps=100):\n",
    "        t = trange(n_steps, desc='loss', leave=True)\n",
    "        for steps in t:\n",
    "            xb, yb = self.generate_batches('train')\n",
    "            logits, loss = self.forward(xb, yb)\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            t.set_description(\"Current loss is %.2f\" % loss.item())\n",
    "            t.refresh()\n",
    "            # self.print(\"Loss at step: \"+str(steps)+\"is \"+str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String:  Program Support Center DEPARTMENT OF HEALTH & HUMAN SERVICES Financial Management Portfolio  Cost Allocation Services 101 9th Street, Suite 4-600 San Francisco, CA 94103-6705 PHONE: (516) 548-8931 EMAIL: CAS-SF@psc.hhs.gov   Memorandum DATE: March 23, 2023 TO: Mary Mitchell, Chief Program Support Center, Debt Collection Center SUBJECT: Account Receivable Based on CAS’ Review of the State of California Pension Refund Proposal ORGANIZATION: State of California  415 L Street, 10th Floor  Sacramento, CA 95814  EIN:52-0395286 I. The following document related to the above review is attached: CAS determination letter dated March 23, 2023  II. Recovery of the disallowance will be accomplished via: Cash $3,996,109.58  Total Disallowance $3,996,109.58  III. Appeals: The grantee does not plan to appeal. If you have any questions, please contact our office at (516) 437-8931. Sincerely, John Doe, Director  Cost Allocation Services Attachment \n",
      "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "Encoded String: tensor([ 0, 34, 56, 53, 47, 56, 41, 51,  0, 36, 59, 54, 54, 53, 56, 58,  0, 22,\n",
      "        45, 52, 58, 45, 56,  0, 23, 24, 34, 20, 35, 37, 31, 24, 32, 37,  0, 33,\n",
      "        25,  0, 27, 24, 20, 30, 37, 27,  0,  2,  0, 27, 38, 31, 20, 32,  0, 36,\n",
      "        24, 35, 39, 28, 22, 24, 36,  0, 25, 49, 52, 41, 52, 43, 49, 41, 50,  0,\n",
      "        31, 41, 52, 41, 47, 45, 51, 45, 52, 58,  0, 34, 53, 56, 58, 46, 53, 50,\n",
      "        49, 53,  0,  0, 22, 53, 57, 58,  0, 20, 50, 50, 53, 43, 41, 58, 49, 53,\n",
      "        52,  0, 36, 45, 56, 60, 49, 43, 45, 57,  0,  9,  8,  9,  0, 17, 58, 48,\n",
      "         0, 36, 58, 56, 45, 45, 58,  5,  0, 36, 59, 49, 58, 45,  0, 12,  6, 14,\n",
      "         8,  8,  0, 36, 41, 52,  0, 25, 56, 41, 52, 43, 49, 57, 43, 53,  5,  0,\n",
      "        22, 20,  0, 17, 12,  9,  8, 11,  6, 14, 15,  8, 13,  0, 34, 27, 33, 32,\n",
      "        24, 18,  0,  3, 13,  9, 14,  4,  0, 13, 12, 16,  6, 16, 17, 11,  9,  0,\n",
      "        24, 31, 20, 28, 30, 18,  0, 22, 20, 36,  6, 36, 25, 19, 54, 57, 43,  7,\n",
      "        48, 48, 57,  7, 47, 53, 60,  0,  0,  0, 31, 45, 51, 53, 56, 41, 52, 44,\n",
      "        59, 51,  0, 23, 20, 37, 24, 18,  0, 31, 41, 56, 43, 48,  0, 10, 11,  5,\n",
      "         0, 10,  8, 10, 11,  0, 37, 33, 18,  0, 31, 41, 56, 62,  0, 31, 49, 58,\n",
      "        43, 48, 45, 50, 50,  5,  0, 22, 48, 49, 45, 46,  0, 34, 56, 53, 47, 56,\n",
      "        41, 51,  0, 36, 59, 54, 54, 53, 56, 58,  0, 22, 45, 52, 58, 45, 56,  5,\n",
      "         0, 23, 45, 42, 58,  0, 22, 53, 50, 50, 45, 43, 58, 49, 53, 52,  0, 22,\n",
      "        45, 52, 58, 45, 56,  0, 36, 38, 21, 29, 24, 22, 37, 18,  0, 20, 43, 43,\n",
      "        53, 59, 52, 58,  0, 35, 45, 43, 45, 49, 60, 41, 42, 50, 45,  0, 21, 41,\n",
      "        57, 45, 44,  0, 53, 52,  0, 22, 20, 36, 63,  0, 35, 45, 60, 49, 45, 61,\n",
      "         0, 53, 46,  0, 58, 48, 45,  0, 36, 58, 41, 58, 45,  0, 53, 46,  0, 22,\n",
      "        41, 50, 49, 46, 53, 56, 52, 49, 41,  0, 34, 45, 52, 57, 49, 53, 52,  0,\n",
      "        35, 45, 46, 59, 52, 44,  0, 34, 56, 53, 54, 53, 57, 41, 50,  0, 33, 35,\n",
      "        26, 20, 32, 28, 40, 20, 37, 28, 33, 32, 18,  0, 36, 58, 41, 58, 45,  0,\n",
      "        53, 46,  0, 22, 41, 50, 49, 46, 53, 56, 52, 49, 41,  0,  0, 12,  9, 13,\n",
      "         0, 30,  0, 36, 58, 56, 45, 45, 58,  5,  0,  9,  8, 58, 48,  0, 25, 50,\n",
      "        53, 53, 56,  0,  0, 36, 41, 43, 56, 41, 51, 45, 52, 58, 53,  5,  0, 22,\n",
      "        20,  0, 17, 13, 16,  9, 12,  0,  0, 24, 28, 32, 18, 13, 10,  6,  8, 11,\n",
      "        17, 13, 10, 16, 14,  0, 28,  7,  0, 37, 48, 45,  0, 46, 53, 50, 50, 53,\n",
      "        61, 49, 52, 47,  0, 44, 53, 43, 59, 51, 45, 52, 58,  0, 56, 45, 50, 41,\n",
      "        58, 45, 44,  0, 58, 53,  0, 58, 48, 45,  0, 41, 42, 53, 60, 45,  0, 56,\n",
      "        45, 60, 49, 45, 61,  0, 49, 57,  0, 41, 58, 58, 41, 43, 48, 45, 44, 18,\n",
      "         0, 22, 20, 36,  0, 44, 45, 58, 45, 56, 51, 49, 52, 41, 58, 49, 53, 52,\n",
      "         0, 50, 45, 58, 58, 45, 56,  0, 44, 41, 58, 45, 44,  0, 31, 41, 56, 43,\n",
      "        48,  0, 10, 11,  5,  0, 10,  8, 10, 11,  0,  0, 28, 28,  7,  0, 35, 45,\n",
      "        43, 53, 60, 45, 56, 62,  0, 53, 46,  0, 58, 48, 45,  0, 44, 49, 57, 41,\n",
      "        50, 50, 53, 61, 41, 52, 43, 45,  0, 61, 49, 50, 50,  0, 42, 45,  0, 41,\n",
      "        43, 43, 53, 51, 54, 50, 49, 57, 48, 45, 44,  0, 60, 49, 41, 18,  0, 22,\n",
      "        41, 57, 48,  0,  1, 11,  5, 17, 17, 14,  5,  9,  8, 17,  7, 13, 16,  0,\n",
      "         0, 37, 53, 58, 41, 50,  0, 23, 49, 57, 41, 50, 50, 53, 61, 41, 52, 43,\n",
      "        45,  0,  1, 11,  5, 17, 17, 14,  5,  9,  8, 17,  7, 13, 16,  0,  0, 28,\n",
      "        28, 28,  7,  0, 20, 54, 54, 45, 41, 50, 57, 18,  0, 37, 48, 45,  0, 47,\n",
      "        56, 41, 52, 58, 45, 45,  0, 44, 53, 45, 57,  0, 52, 53, 58,  0, 54, 50,\n",
      "        41, 52,  0, 58, 53,  0, 41, 54, 54, 45, 41, 50,  7,  0, 28, 46,  0, 62,\n",
      "        53, 59,  0, 48, 41, 60, 45,  0, 41, 52, 62,  0, 55, 59, 45, 57, 58, 49,\n",
      "        53, 52, 57,  5,  0, 54, 50, 45, 41, 57, 45,  0, 43, 53, 52, 58, 41, 43,\n",
      "        58,  0, 53, 59, 56,  0, 53, 46, 46, 49, 43, 45,  0, 41, 58,  0,  3, 13,\n",
      "         9, 14,  4,  0, 12, 11, 15,  6, 16, 17, 11,  9,  7,  0, 36, 49, 52, 43,\n",
      "        45, 56, 45, 50, 62,  5,  0, 29, 53, 48, 52,  0, 23, 53, 45,  5,  0, 23,\n",
      "        49, 56, 45, 43, 58, 53, 56,  0,  0, 22, 53, 57, 58,  0, 20, 50, 50, 53,\n",
      "        43, 41, 58, 49, 53, 52,  0, 36, 45, 56, 60, 49, 43, 45, 57,  0, 20, 58,\n",
      "        58, 41, 43, 48, 51, 45, 52, 58,  0])\n",
      "Decoded String:  Program Support Center DEPARTMENT OF HEALTH & HUMAN SERVICES Financial Management Portfolio  Cost Allocation Services 101 9th Street, Suite 4-600 San Francisco, CA 94103-6705 PHONE: (516) 548-8931 EMAIL: CAS-SF@psc.hhs.gov   Memorandum DATE: March 23, 2023 TO: Mary Mitchell, Chief Program Support Center, Debt Collection Center SUBJECT: Account Receivable Based on CAS’ Review of the State of California Pension Refund Proposal ORGANIZATION: State of California  415 L Street, 10th Floor  Sacramento, CA 95814  EIN:52-0395286 I. The following document related to the above review is attached: CAS determination letter dated March 23, 2023  II. Recovery of the disallowance will be accomplished via: Cash $3,996,109.58  Total Disallowance $3,996,109.58  III. Appeals: The grantee does not plan to appeal. If you have any questions, please contact our office at (516) 437-8931. Sincerely, John Doe, Director  Cost Allocation Services Attachment \n"
     ]
    }
   ],
   "source": [
    "myGPT = customGPT_trainer('data/CAS.pdf')\n",
    "\n",
    "myGPT.print(\"Original String: \" + str(myGPT.original_data))\n",
    "myGPT.print_filler(\"Original String: \"+ str(myGPT.original_data), filler_char='*')\n",
    "myGPT.print(\"Encoded String: \" + str(myGPT.data))\n",
    "myGPT.print(\"Decoded String: \" + str(myGPT.decode(myGPT.data.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGPT.split_data_train_val(thresh=1)\n",
    "xb, yb = myGPT.generate_batches(split='train', batch_size=4, block_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATION BLOCK\n",
    "# batch_size = 4\n",
    "# block_size = 8\n",
    "# print(xb.shape, yb.shape)\n",
    "# for b in range(batch_size):     # Batch Dimension\n",
    "#     for t in range(block_size): # Time Dimension\n",
    "#         context = xb[b, :t+1]\n",
    "#         target = yb[b, t]\n",
    "#         print(f\"when input is \\\"{myGPT.encode(context.tolist())}\\\" the target is {myGPT.decode(target.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out:\ttorch.Size([32, 64])\n",
      "tensor(4.3720, grad_fn=<NllLossBackward0>)\n",
      "tensor([[-0.6710, -0.0761, -0.3269,  ..., -0.3701, -0.5107,  0.5865],\n",
      "        [-0.2375, -0.7223,  0.3216,  ...,  0.4352, -0.4459,  0.4658],\n",
      "        [-0.1131,  0.6481, -0.1300,  ...,  1.2749,  0.4639, -0.0641],\n",
      "        ...,\n",
      "        [-1.7169, -0.3865,  0.8264,  ..., -1.2834, -1.7166, -0.5672],\n",
      "        [-0.8841, -0.5472, -0.0643,  ...,  0.6235, -1.4900, -0.9101],\n",
      "        [ 0.0659, -1.1762, -0.0435,  ..., -0.1965, -0.2361,  0.3353]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out, loss = myGPT.forward(xb, yb)\n",
    "print(\"Out:\\t\" + str(out.shape))\n",
    "print(loss)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " qpOC3qre\n",
      " Gi,EZGe3\n",
      " qVca@tG5\n",
      " ZmE)8faF\n",
      " de1efSLf\n",
      " bI4a(ILe\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "for i in range(6):\n",
    "    print(myGPT.decode(myGPT.generate(idx, max_new_tokens=8)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss is 2.25: 100%|██████████| 3000/3000 [00:11<00:00, 253.75it/s]\n"
     ]
    }
   ],
   "source": [
    "myGPT.train_model(n_steps=max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " M RTEApl\n",
      " MECocame\n",
      " talovitt\n",
      " w raI. 5\n",
      " or 4 Sup\n",
      " d $3iowa\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "for i in range(6):\n",
    "    print(myGPT.decode(myGPT.generate(idx, max_new_tokens=8)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 4, 8, 64\n",
    "x = torch.randn(B,T,C)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow = wei @ x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
